{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bf2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f9607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from dateutil import relativedelta\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673bd613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos dos diretórios raiz                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "# general_path = 'C:/Users/cnalm/OneDrive/Hidroweb'    # Caminho do projeto (Cristiano)\n",
    "# general_path = 'D:/Dados_Nuvem/OneDrive/Hidroweb'   # Colocar aqui o caminho de Filipe\n",
    "general_path = r'C:/Users/linde/OneDrive/Hidroweb'   # Colocar aqui o caminho de Lindemberg\n",
    "\n",
    "states = ['PARÁ', 'AMAPÁ', 'RORAIMA', 'AMAZONAS', 'MARANHÃO', 'CEARÁ', 'PIAUÍ', 'PERNAMBUCO', \n",
    "          'RIO GRANDE DO NORTE', 'TOCANTINS', 'PARAÍBA', 'ACRE', 'ALAGOAS', 'BAHIA', 'MATO GROSSO',\n",
    "          'RONDÔNIA', 'SERGIPE', 'GOIÁS', 'MINAS GERAIS', 'DISTRITO FEDERAL', 'MATO GROSSO DO SUL',\n",
    "          'ESPÍRITO SANTO', 'SÃO PAULO', 'RIO DE JANEIRO', 'PARANÁ', 'SANTA CATARINA', 'RIO GRANDE DO SUL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0de0a",
   "metadata": {},
   "source": [
    "### Reading hdf files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e39df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_pr = pd.read_hdf(general_path + r'/Consolidated Files/BRASIL_RAW_1855_2022_PR450.h5')\n",
    "df_filter_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea40e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gauges = pd.read_hdf(general_path + r'/Consolidated Files/BRASIL_RAW_NOT_CEMADEN_LIST_GAUGES.h5')\n",
    "df_gauges = df_gauges[[\"Code\", \"State\"]]\n",
    "df_gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_pr_state = df_filter_pr.merge(df_gauges, how = 'left', on = 'Code')\n",
    "df_filter_pr_state\n",
    "del df_filter_pr\n",
    "del df_gauges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f39d2",
   "metadata": {},
   "source": [
    "### FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateP(state):\n",
    "    df_filter_pr_state_filter = df_filter_pr_state[(df_filter_pr_state['State'] == state)]\n",
    "    station_list = df_filter_pr_state_filter['Code'].drop_duplicates().reset_index(drop = True, inplace = False).values.tolist()\n",
    "    df_q_gaps = pd.DataFrame(columns = [\"Code\", \"Date\", \"Gaps\"])\n",
    "    count = 0\n",
    "    print(state)\n",
    "    for station in station_list:\n",
    "        count = count + 1\n",
    "        list_code = []\n",
    "        list_date = []\n",
    "        list_gaps = []\n",
    "        print(count, '/', len(station_list))\n",
    "        df_temp_station = df_filter_pr_state_filter[(df_filter_pr_state_filter['Code'] == station)]\n",
    "        year_list = df_temp_station['Year'].drop_duplicates().reset_index(drop = True, inplace = False).values.tolist()\n",
    "        print(year_list)\n",
    "        for year in year_list:\n",
    "            ### FILTERING BY YEAR ###\n",
    "            df_temp_station_year = df_temp_station[(df_temp_station['Year'] == year)]\n",
    "            df_temp_station_year['Month'] = df_temp_station_year['Date'].dt.month\n",
    "            list_month = df_temp_station_year['Month'].drop_duplicates().reset_index(drop = True, inplace = False).values.tolist()\n",
    "            for month in list_month:\n",
    "                df_temp_station_month = df_temp_station_year[(df_temp_station_year['Month'] == month)]\n",
    "                min_date = min(df_temp_station_year['Date'])\n",
    "                max_date = max(df_temp_station_year['Date'])\n",
    "        #         print(df_temp_station_year)\n",
    "                first_day = datetime(year, month, 1)\n",
    "                last_day = first_day + relativedelta.relativedelta(months=1)\n",
    "                date_list = []\n",
    "                today = first_day\n",
    "                while today < last_day:\n",
    "                    date_list.append(today)\n",
    "                    today = today + timedelta(days=1)\n",
    "                df_date_list = pd.DataFrame(date_list, columns=['Date'])\n",
    "                count_ops = len(df_date_list)\n",
    "                ### FILTERING DATE LIST BY OPERATION PERIOD\n",
    "                df_date_list = df_date_list[(df_date_list['Date'] >= min_date) & (df_date_list['Date'] <= max_date)]\n",
    "                df_analysis = df_date_list.merge(df_temp_station_year, how = 'left', on  = 'Date')\n",
    "                df_analysis = df_analysis.sort_values(['Date'], ignore_index=True)\n",
    "                df_void = df_analysis[(df_analysis['Value'].isnull())]\n",
    "                df_void = df_void.sort_values(['Date'], ignore_index=True)\n",
    "                count_gaps = len(df_void)\n",
    "                gap_series = df_analysis['Value'].values.tolist()\n",
    "    #             print(gap_series)\n",
    "                gap_count = 0\n",
    "                gap_max_len = 0\n",
    "                for value in gap_series:\n",
    "                    if math.isnan(value):\n",
    "                        gap_count = gap_count + 1\n",
    "                        # print(value, \"gap count is\", gap_count)\n",
    "                        if gap_count > gap_max_len:\n",
    "                            gap_max_len = gap_count\n",
    "                            # print(value, \"new gap max len\", gap_max_len)\n",
    "                    else:\n",
    "                        gap_count = 0\n",
    "                        # print(value, \"gap count is zero\", gap_count)\n",
    "                q_gap = 100.0 - 100.0 * (((2.0 * count_gaps) + gap_max_len)/count_ops)\n",
    "                if (q_gap < 0.0):\n",
    "                    q_gap = 0.0\n",
    "                # print(\"count_gaps\", count_gaps)\n",
    "                # print(\"count_ops\", count_ops)\n",
    "                # print(\"gap_max_len\", gap_max_len)\n",
    "                # print(\"q_gap\", q_gap)\n",
    "                # print(\"first_day:\", first_day)\n",
    "                # print(\"station:\",  station)\n",
    "                list_code.append(station)\n",
    "                list_date.append(first_day)\n",
    "                list_gaps.append(q_gap)\n",
    "    #     print(list_code)\n",
    "    #     print(list_date)\n",
    "    #     print(list_gaps)\n",
    "        df_station_gaps = pd.DataFrame(list(zip(list_code, list_date, list_gaps)),\n",
    "                                             columns =['Code', 'Date', 'Gaps'])\n",
    "        df_q_gaps = pd.concat([df_q_gaps, df_station_gaps], ignore_index = True)\n",
    "        df_q_gaps['State'] = state\n",
    "        print(df_q_gaps.tail(10))\n",
    "    df_q_gaps.to_hdf(general_path + '/Quality/Q1/Monthly/BRASIL_Q1_GAPS_'+state+'_by_month.h5', 'table_data', mode = 'w', append = False, complevel = 9, encoding=\"cp860\")\n",
    "    data = np.array(df_q_gaps['Gaps'])\n",
    "    plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "    plt.hist(data, bins = 10, edgecolor='black', color = 'grey') #data and number of bins\n",
    "    tnr = {'fontname':'Times New Roman', 'fontsize':12}\n",
    "    plt.xlim(0, 100)\n",
    "#     plt.axvline(data.mean(), color='k', linestyle='dashed', linewidth=2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(general_path+'/Figures/q1_gaps_'+state+'_by_month.jpeg', format='jpeg', dpi=1200, bbox_inches='tight') \n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    print(\"mean\", data.mean())\n",
    "    print(\"median\", statistics.median(data))\n",
    "    print(\"mode\", statistics.mode(data))\n",
    "    # print(df_q_gaps.tail(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29a86b-a418-44f9-a3ca-3675c2fbc45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculateP(\"AMAPÁ\")\n",
    "for state in states:\n",
    "    calculateP(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8ce157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_ACRE_by_month.h5\n",
      "File 2 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_ALAGOAS_by_month.h5\n",
      "File 3 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_AMAPÁ_by_month.h5\n",
      "File 4 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_AMAZONAS_by_month.h5\n",
      "File 5 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_BAHIA_by_month.h5\n",
      "File 6 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_CEARÁ_by_month.h5\n",
      "File 7 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_DISTRITO FEDERAL_by_month.h5\n",
      "File 8 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_ESPÍRITO SANTO_by_month.h5\n",
      "File 9 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_GOIÁS_by_month.h5\n",
      "File 10 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_MARANHÃO_by_month.h5\n",
      "File 11 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_MATO GROSSO DO SUL_by_month.h5\n",
      "File 12 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_MATO GROSSO_by_month.h5\n",
      "File 13 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_MINAS GERAIS_by_month.h5\n",
      "File 14 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_PARANÁ_by_month.h5\n",
      "File 15 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_PARAÍBA_by_month.h5\n",
      "File 16 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_PARÁ_by_month.h5\n",
      "File 17 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_PERNAMBUCO_by_month.h5\n",
      "File 18 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_PIAUÍ_by_month.h5\n",
      "File 19 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_RIO DE JANEIRO_by_month.h5\n",
      "File 20 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_RIO GRANDE DO NORTE_by_month.h5\n",
      "File 21 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_RIO GRANDE DO SUL_by_month.h5\n",
      "File 22 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_RONDÔNIA_by_month.h5\n",
      "File 23 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_RORAIMA_by_month.h5\n",
      "File 24 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_SANTA CATARINA_by_month.h5\n",
      "File 25 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_SERGIPE_by_month.h5\n",
      "File 26 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_SÃO PAULO_by_month.h5\n",
      "File 27 | C:/Users/linde/OneDrive/Hidroweb/Quality/Q1/Monthly\\BRASIL_Q1_GAPS_TOCANTINS_by_month.h5\n",
      "27 files are loaded\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob(general_path + r'/Quality/Q1/Monthly/*.h5')\n",
    "count = 0\n",
    "df = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_hdf(filename)\n",
    "    df.reset_index(inplace=True, drop = True)\n",
    "#     print(df)\n",
    "    if count == 0:\n",
    "        df_total = df.copy(deep = True)\n",
    "    else:\n",
    "        df_total = pd.concat([df_total, df], ignore_index = True)\n",
    "    count = count + 1\n",
    "    print(\"File\", count,\"|\", filename)\n",
    "print(count, \"files are loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4481a4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Gaps</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4266854</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1998-08-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266855</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1998-09-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266856</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1998-10-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266857</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1998-11-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266858</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1998-12-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266859</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1999-01-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266860</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1999-02-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266861</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1999-03-01</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266862</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1999-04-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266863</th>\n",
       "      <td>01348002</td>\n",
       "      <td>1999-05-01</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>TOCANTINS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Code       Date        Gaps      State\n",
       "4266854  01348002 1998-08-01  100.000000  TOCANTINS\n",
       "4266855  01348002 1998-09-01  100.000000  TOCANTINS\n",
       "4266856  01348002 1998-10-01  100.000000  TOCANTINS\n",
       "4266857  01348002 1998-11-01  100.000000  TOCANTINS\n",
       "4266858  01348002 1998-12-01  100.000000  TOCANTINS\n",
       "4266859  01348002 1999-01-01  100.000000  TOCANTINS\n",
       "4266860  01348002 1999-02-01  100.000000  TOCANTINS\n",
       "4266861  01348002 1999-03-01    3.225806  TOCANTINS\n",
       "4266862  01348002 1999-04-01  100.000000  TOCANTINS\n",
       "4266863  01348002 1999-05-01  100.000000  TOCANTINS"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.to_hdf(general_path + r'/Quality/Monthly/BRASIL_Q1_by_month.h5', 'table_data', mode = 'w', append = False, complevel = 9, encoding=\"cp860\")\n",
    "df_total.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
